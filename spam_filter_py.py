# -*- coding: utf-8 -*-
"""spam_filter.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTdcCFQcYkY1KgaxUUTn4uRlX6Sfsikl

**Importing** **Libraries**
"""

import pandas as pd
import numpy as np

"""**Importing Dataset**"""

dataset=pd.read_csv('spam.csv',encoding='latin-1')
x=dataset.iloc[:,[0]]
y=dataset.iloc[:,[1]]

print(x)

print(y)

"""**Encoding into classification(ham(0) or spam(1) )**"""

from sklearn.preprocessing import LabelEncoder
lb=LabelEncoder()
x=lb.fit_transform(x)

print(x)

"""**Stemming**"""

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

reply=[]
for i in range(0,5572):
  text=re.sub('[^a-zA-Z]',' ',dataset['v2'][i])
  text=text.lower()
  text=text.split()
  
  ps=PorterStemmer()
  text=[ps.stem(word) for word in text if not word  in set(stopwords.words('english'))]
  text=' '.join(text)
  reply.append(text)

print(reply)

"""**Converting the collection of texts to a matrix of token counts**"""

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(6200)
x=cv.fit_transform(reply).toarray()
y=dataset.iloc[:,[0]].values

"""**Splitting dataset into train_set and test_set**"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

"""**Training the model**"""

from sklearn.naive_bayes import GaussianNB
classifier=GaussianNB()
classifier.fit(x_train,y_train)

"""**Predicting the Test set results**"""

y_pred=classifier.predict(x_test)
print(np.concatenate( ( y_test.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1) ) ,1))

from sklearn.metrics import accuracy_score,confusion_matrix
cm=confusion_matrix(y_test,y_pred)
print(cm)
accuracy_score(y_test,y_pred)

"""**Predicting a (new)text**"""

new_review = 'The IRS is Trying to Contact You'
new_review = re.sub('[^a-zA-Z]', ' ', new_review)
new_review = new_review.lower()
new_review = new_review.split()

ps = PorterStemmer()
all_stopwords = stopwords.words('english')
all_stopwords.remove('not')
new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]
new_review = ' '.join(new_review)
new_corpus = [new_review]
new_X_test = cv.transform(new_corpus).toarray()
new_y_pred = classifier.predict(new_X_test)
print(new_y_pred)

#https://www.researchgate.net/publication/50211017_Machine_Learning_Methods_for_Spam_E-Mail_Classification